{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r182H7471LI"
   },
   "source": [
    "### Задачи к Лекции 4\n",
    "\n",
    "__Исходные данные__\n",
    "\n",
    "Дан файл **\"mlbootcamp5_train.csv\"**. В нем содержатся данные об опросе 70000 пациентов с целью определения наличия заболеваний сердечно-сосудистой системы (ССЗ). Данные в файле промаркированы и если у человека имееются ССЗ, то значение **cardio** будет равно 1, в противном случае - 0. Описание и значения полей представлены во второй лекции.\n",
    "\n",
    "__Загрузка файла__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "g9DA_5BY71LL",
    "outputId": "32c21d9a-8fbd-4615-8ca9-6f9959d8ada5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>chol_1</th>\n",
       "      <th>chol_2</th>\n",
       "      <th>chol_3</th>\n",
       "      <th>gluc_1</th>\n",
       "      <th>gluc_2</th>\n",
       "      <th>gluc_3</th>\n",
       "      <th>gender_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "id                                                                          \n",
       "0   18393       2     168    62.0    110     80            1     1      0   \n",
       "1   20228       1     156    85.0    140     90            3     1      0   \n",
       "2   18857       1     165    64.0    130     70            3     1      0   \n",
       "3   17623       2     169    82.0    150    100            1     1      0   \n",
       "4   17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "    alco  active  cardio  chol_1  chol_2  chol_3  gluc_1  gluc_2  gluc_3  \\\n",
       "id                                                                         \n",
       "0      0       1       0    True   False   False    True   False   False   \n",
       "1      0       1       1   False   False    True    True   False   False   \n",
       "2      0       0       1   False   False    True    True   False   False   \n",
       "3      0       1       1    True   False   False    True   False   False   \n",
       "4      0       0       0    True   False   False    True   False   False   \n",
       "\n",
       "    gender_bin  \n",
       "id              \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "df = pd.read_csv(\"mlbootcamp5_train.csv\",\n",
    "                 sep=\";\",\n",
    "                 index_col=\"id\")\n",
    "#One-hot кодирование\n",
    "chol = pd.get_dummies(df[\"cholesterol\"], prefix=\"chol\")\n",
    "gluc = pd.get_dummies(df[\"gluc\"], prefix=\"gluc\")\n",
    "df = pd.concat([df, chol, gluc], axis=1)\n",
    "\n",
    "#Делаем пол бинарным признаком\n",
    "df[\"gender_bin\"] = df[\"gender\"].map({1: 0, 2: 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\eliza\\\\ICT\\\\ML\\\\4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bg-BgKNB71LM"
   },
   "source": [
    "## Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOopL0kg71LN"
   },
   "source": [
    "__1. Хоть в sklearn и присутствует реализация метода k-ближайших соседей, я же предлагаю попробовать вам написать его самостоятельно.__\n",
    "\n",
    "* __создать классификатор используя только pandas, numpy и scipy. Гиперпараметром данного классификатора должно быть число ближайших соседей. (Необязательно) можно добавить метрику расстояния и выбор весов.__\n",
    "* __С помощью кросс-валидации найти оптимальное количество ближайших соседей и (необязательно) набор признаков.__\n",
    "\n",
    "Алгоритм работы классификатора:\n",
    " 1. Для заданного прецедент  $\\vec{x}$ мы считаем расстояние до всех прецедентов в обучающей выборке.\n",
    " 2. Сортируем прецеденты по расстоянию до $\\vec{x}$.\n",
    " 3. Отбираем $k$ минимальных значений\n",
    " 4. Устраиваем голосование между отобранными прецедент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запускаем кросс-валидацию на 4 фолдах...\n",
      "  Фолд 1/4...\n",
      "  Фолд 2/4...\n",
      "  Фолд 3/4...\n",
      "  Фолд 4/4...\n",
      "\n",
      "Результаты кросс-валидации (k: средняя точность):\n",
      "k=5: 0.6334\n",
      "k=9: 0.6401\n",
      "k=13: 0.6477\n",
      "k=17: 0.6487\n",
      "k=21: 0.6559\n",
      "k=25: 0.6535\n",
      "\n",
      "---> Нашли лучший параметр k: 21 с точностью 0.6559\n",
      "\n",
      "Обучаем итоговую модель с k=21...\n"
     ]
    }
   ],
   "source": [
    "#БИБЛИОТЕКИ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import mode\n",
    "\n",
    "#Классификатор\n",
    "class MyKNNClassifier:\n",
    "    \"\"\"\n",
    "    Классификатор методом k-ближайших соседей.\n",
    "    Оптимизирован для работы с большими данными, чтобы не падать с MemoryError.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=5, metric='euclidean', weights='uniform'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        \"Обучение\" модели. Просто запоминаем обучающие данные.\n",
    "        \"\"\"\n",
    "        self._train_data = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "        self._train_labels = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "        self._classes = np.unique(self._train_labels)\n",
    "\n",
    "    def predict(self, X_test, batch_size=1000):\n",
    "        \"\"\"\n",
    "        Предсказание меток для новых данных с использованием батчей для экономии памяти.\n",
    "        \"\"\"\n",
    "        X_test_np = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
    "        num_test_samples = X_test_np.shape[0]\n",
    "        \n",
    "        all_predictions = []\n",
    "        \n",
    "        #Проходим по тестовым данным порциями (батчами)\n",
    "        for i in range(0, num_test_samples, batch_size):\n",
    "            X_batch = X_test_np[i : i + batch_size]\n",
    "            \n",
    "            #Считаем расстояния только для текущего батча\n",
    "            distances = cdist(X_batch, self._train_data, metric=self.metric)\n",
    "            \n",
    "            k_nearest_indices = np.argsort(distances, axis=1)[:, :self.k]\n",
    "            k_nearest_labels = self._train_labels[k_nearest_indices]\n",
    "\n",
    "            if self.weights == 'uniform':\n",
    "                batch_preds, _ = mode(k_nearest_labels, axis=1, keepdims=False)\n",
    "                all_predictions.append(batch_preds)\n",
    "                \n",
    "            elif self.weights == 'distance':\n",
    "                k_nearest_distances = np.take_along_axis(distances, k_nearest_indices, axis=1)\n",
    "                epsilon = 1e-6\n",
    "                vote_weights = 1 / (k_nearest_distances + epsilon)\n",
    "                \n",
    "                batch_preds = []\n",
    "                for obj_idx in range(X_batch.shape[0]):\n",
    "                    class_scores = {cls: 0 for cls in self._classes}\n",
    "                    for neighbor_idx in range(self.k):\n",
    "                        neighbor_label = k_nearest_labels[obj_idx, neighbor_idx]\n",
    "                        neighbor_weight = vote_weights[obj_idx, neighbor_idx]\n",
    "                        class_scores[neighbor_label] += neighbor_weight\n",
    "                    \n",
    "                    best_class = max(class_scores, key=class_scores.get)\n",
    "                    batch_preds.append(best_class)\n",
    "                \n",
    "                all_predictions.append(np.array(batch_preds))\n",
    "            else:\n",
    "                raise ValueError(\"Неизвестный тип весов. Используйте 'uniform' или 'distance'.\")\n",
    "        \n",
    "        return np.concatenate(all_predictions)\n",
    "\n",
    "#Кросс-валидация\n",
    "def perform_cross_validation(X, y, k_range, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Проводит кросс-валидацию для нашего KNN, чтобы найти лучший k.\n",
    "    \"\"\"\n",
    "    print(f\"Запускаем кросс-валидацию на {cv_folds} фолдах...\")\n",
    "    \n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    fold_indices = np.array_split(indices, cv_folds)\n",
    "    \n",
    "    k_scores = {k: [] for k in k_range}\n",
    "    \n",
    "    for i in range(cv_folds):\n",
    "        print(f\"  Фолд {i+1}/{cv_folds}...\")\n",
    "        val_idx = fold_indices[i]\n",
    "        train_idx = np.concatenate([fold_indices[j] for j in range(cv_folds) if j != i])\n",
    "        \n",
    "        X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val_fold, y_val_fold = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        for k in k_range:\n",
    "            model = MyKNNClassifier(k=k, weights='distance') # Можно поменять на 'uniform'\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            \n",
    "            # Важно: здесь вызывается наш новый `predict` с батчами\n",
    "            y_pred = model.predict(X_val_fold) \n",
    "            \n",
    "            accuracy = np.mean(y_pred == y_val_fold.values)\n",
    "            k_scores[k].append(accuracy)\n",
    "\n",
    "    mean_k_scores = {k: np.mean(scores) for k, scores in k_scores.items()}\n",
    "    return mean_k_scores\n",
    "\n",
    "\n",
    "df = pd.read_csv('mlbootcamp5_train.csv', sep=';') \n",
    "\n",
    "try:\n",
    "    #Пытаемся загрузить реальный датасет\n",
    "    df = pd.read_csv('mlbootcamp5_train.csv', sep=';')\n",
    "    df = df.drop(columns=['id']) # Удаляем ненужный столбец id\n",
    "    # Возьмем только часть данных, чтобы кросс-валидация не шла вечность\n",
    "    df = df.sample(n=10000, random_state=42) \n",
    "except FileNotFoundError:\n",
    "    print(\"Файл 'mlbootcamp5_train.csv' не найден. Создаем фейковые данные для демонстрации.\")\n",
    "    from sklearn.datasets import make_classification\n",
    "    X_fake, y_fake = make_classification(n_samples=5000, n_features=11, n_informative=8, n_redundant=0, n_classes=2, random_state=42)\n",
    "    features_list = ['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo',\n",
    "                     'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "    df = pd.DataFrame(X_fake, columns=features_list)\n",
    "    df['cardio'] = y_fake\n",
    "\n",
    "\n",
    "#Выбираем признаки и целевой столбец\n",
    "features = df.columns.drop('cardio').tolist()\n",
    "target = 'cardio'\n",
    "\n",
    "X_data = df[features]\n",
    "y_data = df[target]\n",
    "\n",
    "#Нормализуем данные\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_data_scaled = pd.DataFrame(scaler.fit_transform(X_data), columns=features)\n",
    "\n",
    "\n",
    "#Задаем диапазон k, который хотим проверить\n",
    "k_values_to_test = list(range(5, 26, 4)) # Проверим k = 5, 9, 13, 17, 21, 25\n",
    "\n",
    "#Запускаем нашу кросс-валидацию\n",
    "#Используем нормализованные данные X_data_scaled\n",
    "cv_scores = perform_cross_validation(X_data_scaled, y_data, k_values_to_test, cv_folds=4) # 4 фолда, чтобы было быстрее\n",
    "\n",
    "print(\"\\nРезультаты кросс-валидации (k: средняя точность):\")\n",
    "for k, score in cv_scores.items():\n",
    "    print(f\"k={k}: {score:.4f}\")\n",
    "\n",
    "#Находим k с наилучшим результатом\n",
    "best_k_found = max(cv_scores, key=cv_scores.get)\n",
    "print(f\"\\n---> Нашли лучший параметр k: {best_k_found} с точностью {cv_scores[best_k_found]:.4f}\")\n",
    "\n",
    "#Обучаем финальную модель на всех данных с лучшим k\n",
    "print(f\"\\nОбучаем итоговую модель с k={best_k_found}...\")\n",
    "final_knn_model = MyKNNClassifier(k=best_k_found, weights='distance')\n",
    "#Обучаем на полных нормализованных данных\n",
    "final_knn_model.fit(X_data_scaled, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iXS9ETX71LN"
   },
   "source": [
    "**Комментарии:** Ваши комментарии здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIyL_rFX71LO"
   },
   "source": [
    "**2. Определить какой из трех классификаторов (kNN, наивный Байес, решающее дерево) лучший в каждой метрике по отдельности: accuracy, F1-мера, ROC AUC, функция потерь. Использовать набор признаков: 'age', 'weight', 'height', 'ap_lo', 'ap_hi'.**\n",
    "\n",
    "**(Необязательно) Найти оптимальный набор признаков.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FE3zzzu71LO",
    "outputId": "ead29c2c-7e36-469b-c46f-8a2287292342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  F1-score   ROC AUC   Log Loss\n",
      "kNN            0.679143  0.672149  0.723429   2.365549\n",
      "Naive Bayes    0.541238  0.213551  0.667530   0.785127\n",
      "Decision Tree  0.617619  0.617619  0.617655  13.769303\n",
      "\n",
      "Лучший классификатор по каждой метрике:\n",
      "Accuracy              kNN\n",
      "F1-score              kNN\n",
      "ROC AUC               kNN\n",
      "Log Loss    Decision Tree\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "\n",
    "#Подготовка данных\n",
    "\n",
    "# Предположим, что df — ваш DataFrame\n",
    "features = ['age', 'weight', 'height', 'ap_lo', 'ap_hi']\n",
    "target = 'cardio'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Разбиваем на тренировочную и тестовую выборки (например, 70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Обучение моделей\n",
    "\n",
    "# kNN (например, с k=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Наивный Байес\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Решающее дерево\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#Предсказания и оценка\n",
    "\n",
    "models = {\n",
    "    'kNN': knn,\n",
    "    'Naive Bayes': nb,\n",
    "    'Decision Tree': dt\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]  # Вероятности положительного класса\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    loss = log_loss(y_test, y_proba)\n",
    "\n",
    "    results[name] = {\n",
    "        'Accuracy': acc,\n",
    "        'F1-score': f1,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'Log Loss': loss\n",
    "    }\n",
    "\n",
    "#Вывод результатов и определение лучших\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(df_results)\n",
    "\n",
    "# Определение лучших по каждой метрике\n",
    "best_metrics = df_results.idxmax()\n",
    "print(\"\\nЛучший классификатор по каждой метрике:\")\n",
    "print(best_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyaQK15471LO"
   },
   "source": [
    "**Комментарии:** Ваши комментарии здесь."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
